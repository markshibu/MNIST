{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTfyOMZz8JBv",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "trainset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "testset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset,  batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5UBswQPRKqW"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,4,5)\n",
    "        self.conv2 = nn.Conv2d(4,10,5)\n",
    "        self.fc1 = nn.Linear(10*4*4, 60)\n",
    "        self.fc2 = nn.Linear(60,10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.dropout(F.relu(self.conv1(x))) #4,24,24\n",
    "        x = F.max_pool2d(x, 2, 2) #4,12,12\n",
    "        x = self.dropout(F.relu(self.conv2(x))) #10,8,8\n",
    "        x = F.max_pool2d(x, 2, 2) #10,4,4\n",
    "        x = x.view(-1,10*4*4)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return F.log_softmax(self.fc2(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {:2d} [{:5d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target).item() \n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34_mrn2ERIPS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  0 [    0/60000 (0%)]\tLoss: 2.110638\n",
      "Train Epoch:  0 [ 4000/60000 (7%)]\tLoss: 0.061536\n",
      "Train Epoch:  0 [ 8000/60000 (13%)]\tLoss: 0.034020\n",
      "Train Epoch:  0 [12000/60000 (20%)]\tLoss: 0.391845\n",
      "Train Epoch:  0 [16000/60000 (27%)]\tLoss: 0.002954\n",
      "Train Epoch:  0 [20000/60000 (33%)]\tLoss: 0.029037\n",
      "Train Epoch:  0 [24000/60000 (40%)]\tLoss: 0.000443\n",
      "Train Epoch:  0 [28000/60000 (47%)]\tLoss: 0.469328\n",
      "Train Epoch:  0 [32000/60000 (53%)]\tLoss: 0.010578\n",
      "Train Epoch:  0 [36000/60000 (60%)]\tLoss: 0.486472\n",
      "Train Epoch:  0 [40000/60000 (67%)]\tLoss: 0.004031\n",
      "Train Epoch:  0 [44000/60000 (73%)]\tLoss: 0.727852\n",
      "Train Epoch:  0 [48000/60000 (80%)]\tLoss: 0.000084\n",
      "Train Epoch:  0 [52000/60000 (87%)]\tLoss: 0.011323\n",
      "Train Epoch:  0 [56000/60000 (93%)]\tLoss: 0.190573\n",
      "\n",
      "Test set: Average loss: 0.0782, Accuracy: 9749/10000 (97%)\n",
      "\n",
      "Train Epoch:  1 [    0/60000 (0%)]\tLoss: 0.000502\n",
      "Train Epoch:  1 [ 4000/60000 (7%)]\tLoss: 0.006451\n",
      "Train Epoch:  1 [ 8000/60000 (13%)]\tLoss: 0.002034\n",
      "Train Epoch:  1 [12000/60000 (20%)]\tLoss: 0.006217\n",
      "Train Epoch:  1 [16000/60000 (27%)]\tLoss: 0.001375\n",
      "Train Epoch:  1 [20000/60000 (33%)]\tLoss: 0.001317\n",
      "Train Epoch:  1 [24000/60000 (40%)]\tLoss: 0.064568\n",
      "Train Epoch:  1 [28000/60000 (47%)]\tLoss: 0.002909\n",
      "Train Epoch:  1 [32000/60000 (53%)]\tLoss: 0.112633\n",
      "Train Epoch:  1 [36000/60000 (60%)]\tLoss: 0.010476\n",
      "Train Epoch:  1 [40000/60000 (67%)]\tLoss: 0.000089\n",
      "Train Epoch:  1 [44000/60000 (73%)]\tLoss: 0.001317\n",
      "Train Epoch:  1 [48000/60000 (80%)]\tLoss: 0.042907\n",
      "Train Epoch:  1 [52000/60000 (87%)]\tLoss: 0.122242\n",
      "Train Epoch:  1 [56000/60000 (93%)]\tLoss: 0.000153\n",
      "\n",
      "Test set: Average loss: 0.0786, Accuracy: 9761/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available(): print(torch.cuda.get_device_name(0))\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"mnist_cnn1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = Net()\n",
    "loaded_model.load_state_dict(torch.load('mnist_cnn1.pt'))\n",
    "test(loaded_model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
