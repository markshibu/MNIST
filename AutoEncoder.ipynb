{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),])\n",
    "                                #transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "trainset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "testset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset,  batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 3), \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28*28)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla K80\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available(): print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder().to(device)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 15000 0.0378547337166965\n",
      "999 15000 0.037443028450012204\n",
      "1499 15000 0.03747977417334914\n",
      "1999 15000 0.03758530837111175\n",
      "2499 15000 0.03752957721240818\n",
      "2999 15000 0.03735070521384477\n",
      "3499 15000 0.03745855295285583\n",
      "3999 15000 0.037031309310346844\n",
      "4499 15000 0.03737496289424598\n",
      "4999 15000 0.03701642127335072\n",
      "5499 15000 0.03805931902676821\n",
      "5999 15000 0.03680965966172516\n",
      "6499 15000 0.03653017470985651\n",
      "6999 15000 0.03715862655825913\n",
      "7499 15000 0.0362178839892149\n",
      "7999 15000 0.03673516898043454\n",
      "8499 15000 0.03714368417672813\n",
      "8999 15000 0.0367428810428828\n",
      "9499 15000 0.036140213921666144\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-2f01f3fc9222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtmp\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "n = 500\n",
    "for epoch in range(2):\n",
    "    tmp=0\n",
    "    for step, (x, label) in enumerate(train_loader):\n",
    "        x, label = x.to(device),label.to(device)\n",
    "        encoded, decoded = autoencoder(x.view(-1, 28*28))\n",
    "        loss = criterion(decoded, x.view(-1, 28*28))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tmp+=loss.item()\n",
    "        if step%n == n-1:\n",
    "            print(step,len(train_loader),tmp/n)\n",
    "            tmp=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder_Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder_Conv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,4,3)\n",
    "        self.conv2 = nn.Conv2d(4,10,3)\n",
    "        self.fc1 = nn.Linear(10*5*5, 60)\n",
    "        self.fc2 = nn.Linear(60,10)\n",
    "        \n",
    "        self.fc3 = nn.Linear(10, 60)\n",
    "        self.fc4 = nn.Linear(60,10*5*5)\n",
    "        self.conv3 = nn.ConvTranspose2d(10,4,3)\n",
    "        self.conv4 = nn.ConvTranspose2d(4,1,3)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.unpool = nn.MaxUnpool2d(2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.conv1(x))) #4,26,26\n",
    "        x,indices1 = F.max_pool2d(x, 2, 2, return_indices=True) #4,13,13\n",
    "        x = self.dropout(F.relu(self.conv2(x))) #10,11,11\n",
    "        x,indices2 = F.max_pool2d(x, 2, 2, return_indices=True) #10,5,5\n",
    "        x = x.view(-1,10*5*5)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        encoded = self.fc2(x)\n",
    "        \n",
    "        x = self.dropout(F.relu(self.fc3(encoded)))\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "        x = x.view(-1,10,5,5)\n",
    "        x = self.unpool(x, indices=indices2, output_size=torch.Size([-1, 10, 11, 11]))\n",
    "        x = self.dropout(F.relu(self.conv3(x)))\n",
    "        x = self.unpool(x, indices=indices1, output_size=torch.Size([-1, 4, 26, 26]))\n",
    "        decoded = self.conv4(x)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_conv = AutoEncoder_Conv().to(device)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 15000 0.02888400765135884\n",
      "999 15000 0.028779430631548166\n",
      "1499 15000 0.028758681792765854\n",
      "1999 15000 0.028908857537433504\n",
      "2499 15000 0.02908941739052534\n",
      "2999 15000 0.028395284652709962\n",
      "3499 15000 0.028714566305279732\n",
      "3999 15000 0.02874299100600183\n",
      "4499 15000 0.02918004709854722\n",
      "4999 15000 0.029308837816119194\n",
      "5499 15000 0.028464038353413344\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-ed4d21b68c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "optimizer = torch.optim.Adam(autoencoder_conv.parameters(), lr=0.001)\n",
    "for epoch in range(2):\n",
    "    tmp = 0\n",
    "    for step, (x, label) in enumerate(train_loader):\n",
    "        x, label = x.to(device),label.to(device)\n",
    "        encoded, decoded = autoencoder_conv(x)\n",
    "        loss = criterion(decoded, x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tmp+=loss.item()\n",
    "        if step%n == n-1:\n",
    "            print(step,len(train_loader),tmp/n)\n",
    "            tmp=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_(s,autoencoder_conv):\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(s.numpy()[0])\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    s = s.view(1,1,28,28)\n",
    "    autoencoder_conv.eval()\n",
    "    encoded, decoded = autoencoder_conv(s.to(device))\n",
    "    plt.imshow(decoded.cpu().detach().numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 184,
       "width": 370
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_(trainset[151][0],autoencoder_conv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
